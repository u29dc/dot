# Codex Global Configuration
# ~/.codex/config.toml
# Docs: https://raw.githubusercontent.com/openai/codex/refs/heads/main/docs/config.md

# CORE SETTINGS
model = "gpt-5.2-codex"
model_reasoning_effort = "high"
model_reasoning_summary = "detailed"
model_verbosity = "high"
sandbox_mode = "workspace-write"
approval_policy = "on-request"

# Context window optimizationtool_output_token_limit = 25000
model_auto_compact_token_limit = 233000

# FEATURES
[features]
unified_exec = true
apply_patch_freeform = true
web_search_request = true
skills = true

# SANDBOX SETTINGS
[sandbox_workspace_write]
network_access = true

# SHELL ENVIRONMENT
[shell_environment_policy]
inherit = "all"
ignore_default_excludes = false

# TRUSTED PROJECTS
[projects."/Users/han/Git"]
trust_level = "trusted"

# MCP SERVERS
[mcp_servers.svelte]
command = "bunx"
args = ["@sveltejs/mcp"]

[mcp_servers.github]
command = "bunx"
args = ["-y", "@modelcontextprotocol/server-github"]
env_vars = ["GITHUB_TOKEN"]

# HISTORY
[history]
persistence = "save-all"
max_bytes = 10485760
