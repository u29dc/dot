# Codex Global Configuration
# ~/.codex/config.toml
# https://raw.githubusercontent.com/openai/codex/refs/heads/main/docs/config.md
# https://developers.openai.com/codex/config-reference

# CORE SETTINGS
model = "gpt-5.3-codex"
model_reasoning_effort = "xhigh"
model_reasoning_summary = "detailed"
model_verbosity = "high"
sandbox_mode = "workspace-write"
approval_policy = "never"
suppress_unstable_features_warning = true
web_search = "live"
show_raw_agent_reasoning = true
file_opener = "cursor"

# Context window optimization
tool_output_token_limit = 25000
model_auto_compact_token_limit = 233000
personality = "pragmatic"

# FEATURES
[features]
unified_exec = true
apply_patch_freeform = true
skills = true
shell_snapshot = true

# SANDBOX SETTINGS
[sandbox_workspace_write]
network_access = true

# SHELL ENVIRONMENT
[shell_environment_policy]
inherit = "all"
ignore_default_excludes = false

# TRUSTED PROJECTS
[projects."/Users/han/Git"]
trust_level = "trusted"

# MCP SERVERS
[mcp_servers.svelte]
command = "bunx"
args = ["@sveltejs/mcp"]

[mcp_servers.github]
command = "bunx"
args = ["-y", "@modelcontextprotocol/server-github"]
env_vars = ["GITHUB_TOKEN"]

[mcp_servers.notion]
url = "https://mcp.notion.com/mcp"

# HISTORY
[history]
persistence = "save-all"
max_bytes = 10485760

[notice]
hide_full_access_warning = true
